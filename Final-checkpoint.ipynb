{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f65267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import statsmodels.api as sm\n",
    "import missingno as msno\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import shapiro\n",
    "#from scipy.stats.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "#from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "#from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "print(\"RUTA de IMAGENeS\")\n",
    "\n",
    "filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "filterwarnings(\"ignore\", category=FutureWarning) \n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Meat_Data_Data = Path(\"C:/Users/David/Documents/PROYECTO/CarneDataset/train/CLASS_02\")\n",
    "# main path\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "JPG_Path = list(Meat_Data_Data.glob(r\"*/*.jpg\"))\n",
    "# jpg path\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "print(JPG_Path[0:5])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], JPG_Path))\n",
    "# splitting fresh and spoiled\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Labels.count(\"Fresh\"))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Labels.count(\"Spoiled\"))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "File_Path = pd.Series(JPG_Path, name=\"JPG\").astype(str)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(File_Path.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Label_Name = pd.Series(Labels, name=\"CATEGORY\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Label_Name.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Label_Name.value_counts())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Main_Data = pd.concat([File_Path, Label_Name], axis=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Main_Data.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Main_Data[\"CATEGORY\"].value_counts())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Fresh_Meat = Main_Data[Main_Data[\"CATEGORY\"] == \"Fresh\"]\n",
    "Spoiled_Meat = Main_Data[Main_Data[\"CATEGORY\"] == \"Spoiled\"]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Fresh_Meat.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Spoiled_Meat.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(plt.imread(Main_Data[\"JPG\"][1]))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#figure = plt.figure(figsize=(8,8))\n",
    "#plt.imshow(plt.imread(Main_Data[\"JPG\"][2]))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#figure = plt.figure(figsize=(8,8))\n",
    "#plt.imshow(plt.imread(Fresh_Meat[\"JPG\"][10]))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#figure = plt.figure(figsize=(8,8))\n",
    "#plt.imshow(plt.imread(Spoiled_Meat[\"JPG\"][1]))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(8, 8), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(Main_Data[\"JPG\"][i]))\n",
    "    ax.set_title(Main_Data[\"CATEGORY\"][i])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Train_Data, Test_Data = train_test_split(Main_Data, train_size=0.8, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Train_Data.shape)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Data_Generator = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Train_Gen = Data_Generator.flow_from_dataframe(dataframe=Train_Data,\n",
    "                                               x_col=\"JPG\",\n",
    "                                               y_col=\"CATEGORY\",\n",
    "                                               shuffle=True,seed=42,\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               batch_size=32,\n",
    "                                               subset=\"training\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Train_Gen.classes[0:20])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Train_Gen.split)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Test_Gen = Data_Generator.flow_from_dataframe(dataframe=Test_Data,\n",
    "                                               x_col=\"JPG\",\n",
    "                                               y_col=\"CATEGORY\",\n",
    "                                               shuffle=False,seed=42,\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               batch_size=32)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Test_Gen.classes[0:20])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Test_Gen.split)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Validation_Gen = Data_Generator.flow_from_dataframe(dataframe=Train_Data,\n",
    "                                               x_col=\"JPG\",\n",
    "                                               y_col=\"CATEGORY\",\n",
    "                                               shuffle=True,seed=42,\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               batch_size=32,\n",
    "                                               subset=\"validation\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Validation_Gen.classes[0:20])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Validation_Gen.split)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  \n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Flatten(input_shape=(113,)),\n",
    "  \n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  \n",
    "  tf.keras.layers.Dense(2,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Call_Back = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "ANN_Model = model.fit(Train_Gen,\n",
    "                     validation_data=Validation_Gen,\n",
    "                     epochs=10,batch_size=5,\n",
    "                     callbacks=Call_Back)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Model_Results = model.evaluate(Test_Gen,verbose=False)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(ANN_Model.history[\"accuracy\"])\n",
    "plt.plot(ANN_Model.history[\"val_accuracy\"])\n",
    "plt.ylabel(\"ACCURACY\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "HistoryDict = ANN_Model.history\n",
    "\n",
    "val_losses = HistoryDict[\"val_loss\"]\n",
    "val_acc = HistoryDict[\"val_accuracy\"]\n",
    "acc = HistoryDict[\"accuracy\"]\n",
    "losses = HistoryDict[\"loss\"]\n",
    "epochs = range(1,len(val_losses)+1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(epochs,val_losses,\"k-\",label=\"LOSS\")\n",
    "plt.plot(epochs,val_acc,\"r\",label=\"ACCURACY\")\n",
    "plt.title(\"LOSS & ACCURACY\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"Loss & Acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(epochs,acc,\"k-\",label=\"ACCURACY\")\n",
    "plt.plot(epochs,val_acc,\"r\",label=\"ACCURACY VAL\")\n",
    "plt.title(\"ACCURACY & ACCURACY VAL\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"ACCURACY & ACCURACY VAL\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(epochs, losses, \"k-\", label=\"LOSS\")\n",
    "plt.plot(epochs, val_losses, \"r\", label=\"LOSS VAL\")\n",
    "plt.title(\"LOSS & LOSS VAL\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS & LOSS VAL\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Dict_Summary = pd.DataFrame(ANN_Model.history)\n",
    "Dict_Summary.plot()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Model_Predict = model.predict(Test_Gen)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Model_Predict = np.argmax(Model_Predict,axis=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Predict_Label = (Test_Gen.class_indices)\n",
    "Predict_Label = dict((v, k) for k, v in Predict_Label.items())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Model_Predict = [Predict_Label[k] for k in Model_Predict]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(Model_Predict[:10])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Test_Results = list(Test_Data[\"CATEGORY\"])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Class_Report = classification_report(Test_Results,Model_Predict)\n",
    "print(Class_Report)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Conf_Report = confusion_matrix(Test_Results,Model_Predict, normalize=\"true\")\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "sns.heatmap(Conf_Report,vmax=1,center=0,vmin=-1,annot=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=8,\n",
    "                         ncols=8,\n",
    "                         figsize=(15, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(Test_Data[\"JPG\"].iloc[i]))\n",
    "    ax.set_title(f\"TEST:{Test_Data.CATEGORY.iloc[i]}\\n PREDICTION:{Model_Predict[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "get_ipython().system(' pip install xgboost')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "get_ipython().system(' pip3 install xgboost')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "get_ipython().system(' conda install -c conda-forge xgboost')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import xgboost\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
